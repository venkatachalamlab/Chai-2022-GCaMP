{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from utils.utils import get_slice, extract_traces\n",
    "from annotation.annotations_io import load_annotations, save_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flow_file(flow_file_path):\n",
    "    flow, index = [], []\n",
    "\n",
    "    if os.path.exists(flow_file_path):\n",
    "        with open(flow_file_path, \"r\") as f:\n",
    "            data = csv.reader(f)\n",
    "            for row in data:\n",
    "                flow.append(row[1])\n",
    "                index.append(int(row[0]))\n",
    "    else:\n",
    "        flow = [\"none\"]\n",
    "        index = [0]\n",
    "\n",
    "    return flow, index\n",
    "\n",
    "def get_ids(dataset_path):\n",
    "    A, W = load_annotations(Path(dataset_path)/\"processed\")\n",
    "    return list(W.df[\"id\"]), list([name.decode() for name in W.df[\"name\"]])\n",
    "\n",
    "def get_flow(dataset):\n",
    "    flow_file = os.path.join(dataset, \"processed\", \"flow_file.txt\")\n",
    "    flow, frames = load_flow_file(flow_file)\n",
    "    return frames, flow\n",
    "\n",
    "def load_traces(dataset, **kwargs):\n",
    "    \n",
    "    \n",
    "    traces_folder = os.path.join(dataset,\"processed\", \"traces\")\n",
    "    \n",
    "    if 'trace_file' in kwargs.keys():\n",
    "        traces_file = os.path.join(traces_folder, kwargs['trace_file'])\n",
    "        \n",
    "    elif os.path.isfile(os.path.join(traces_folder, \"traces.npy\")):\n",
    "        traces_file = os.path.join(traces_folder, \"traces.npy\")\n",
    "        \n",
    "    elif os.path.isfile(os.path.join(traces_folder, \"tracked_traces.npy\")):\n",
    "        traces_file = os.path.join(traces_folder, \"tracked_traces.npy\")\n",
    "        \n",
    "    else:\n",
    "        traces_file = os.path.join(traces_folder, \"not_tracked_traces.npy\")\n",
    "        \n",
    "    return np.load(traces_file)\n",
    "\n",
    "def get_odor_trace(dataset, odor, **kwargs):\n",
    "    (frames,flow) = get_flow(dataset)\n",
    "    traces = load_traces(dataset, **kwargs)\n",
    "    odor_idx = (int(frames[flow.index(odor)]), int(frames[flow.index(odor)+1]))\n",
    "    \n",
    "    t_idx = np.s_[odor_idx[0]-buffer_idx[0]:odor_idx[1]+buffer_idx[1]]\n",
    "    return traces[:, t_idx]\n",
    "\n",
    "def get_neuron_traces(paths, neuron, odor, **kwargs):\n",
    "\n",
    "    shape = get_odor_trace(paths[0], odor, **kwargs)[0].shape\n",
    "    neuron_traces = []\n",
    "    \n",
    "    for path in paths:\n",
    "        (ids, names) = get_ids(path)\n",
    "        try:\n",
    "            idx = ids[names.index(neuron)]\n",
    "            path_trace = get_odor_trace(path, odor, **kwargs)[idx]\n",
    "            neuron_traces.append(path_trace)\n",
    "            print(path, path_trace.shape)\n",
    "        except ValueError:\n",
    "            empty_trace = np.zeros(shape)\n",
    "            empty_trace[:] = np.nan\n",
    "            neuron_traces.append(empty_trace)\n",
    "            \n",
    "    neuron_traces = np.stack(neuron_traces, 0)\n",
    "    return neuron_traces\n",
    "\n",
    "def get_all_neuron_traces(paths, all_names, odor, **kwargs):\n",
    "    odor_traces = []\n",
    "    for name in all_names:\n",
    "        odor_traces.append(get_neuron_traces(paths, name, odor), **kwargs)\n",
    "    return odor_traces\n",
    "\n",
    "\n",
    "buffer_idx = [60, 60] \n",
    "colors_dict = {\n",
    "    \"Control\": \"#B2BABB\",\n",
    "    \"Pheromone\": \"#F7DC6F\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aib_odors = ['Pheromone', 'Control']\n",
    "aib_names = ['AIBL', 'AIBR']\n",
    "aib_paths = [\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\5\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\5_2\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\6\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\7\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\8\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\8_2\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\9\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\9_2\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\10\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\10_2\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\11_2\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\12\"),\n",
    "    Path(r\"X:\\Maede\\data\\daure\\20211008\\12_2\")]\n",
    "\n",
    "for path in aib_paths:\n",
    "    extract_traces(path)\n",
    "\n",
    "def get_odor_trace_pher(dataset, odor):\n",
    "    p = Path(dataset)/'traces/traces.npy'\n",
    "    traces = np.load(p)\n",
    "    flow_file = os.path.join(dataset, \"flow_file.txt\")\n",
    "    flow, frames = load_flow_file(flow_file)\n",
    "    odor_idx = (int(frames[flow.index(odor)]), int(frames[flow.index(odor)+1]))\n",
    "    t_idx = np.s_[odor_idx[0]-buffer_idx[0]:odor_idx[1]+buffer_idx[1]]\n",
    "    return traces[:, t_idx]\n",
    "\n",
    "def get_trace_pher(dataset):\n",
    "    p = Path(dataset)/'traces/traces.npy'\n",
    "    traces = np.load(p)\n",
    "    flow_file = os.path.join(dataset, \"flow_file.txt\")\n",
    "    flow, frames = load_flow_file(flow_file)\n",
    "    odor_idx = (int(frames[flow.index('Pheromone')]), int(frames[flow.index('Control')+1]))\n",
    "    t_idx = np.s_[odor_idx[0]-buffer_idx[0]:odor_idx[1]+buffer_idx[1]]\n",
    "    return traces[:, t_idx]\n",
    "\n",
    "def get_trace_process(dataset):\n",
    "    p = Path(dataset)/'traces/processes_traces.npy'\n",
    "    traces = np.load(p)\n",
    "    flow_file = os.path.join(dataset, \"flow_file.txt\")\n",
    "    flow, frames = load_flow_file(flow_file)\n",
    "    odor_idx = (int(frames[flow.index('Pheromone')]), int(frames[flow.index('Control')+1]))\n",
    "    t_idx = np.s_[odor_idx[0]-buffer_idx[0]:odor_idx[1]+buffer_idx[1]]\n",
    "    return traces[0, t_idx]\n",
    "\n",
    "times = list(range(buffer_idx[0]+buffer_idx[1]+240))\n",
    "df = pd.DataFrame()\n",
    "dic = {}\n",
    "\n",
    "for path in aib_paths:\n",
    "    path = Path(path)/'processed'\n",
    "    A, W = load_annotations(path)\n",
    "    names = [name.decode() for name in W.df[\"name\"]]\n",
    "    flow_file = os.path.join(path, \"flow_file.txt\")\n",
    "    flow, _ = load_flow_file(flow_file)\n",
    "    flow = [f  for f in flow if f!='CTX']\n",
    "    dic['animal'] = str(path).split('\\\\')[-2]\n",
    "    \n",
    "    \n",
    "    trace = get_trace_process(path)\n",
    "\n",
    "    dic['neuron'] = 'AIB_process'\n",
    "    \n",
    "    bl = np.nanmean(trace[buffer_idx[0]-20:buffer_idx[0]])\n",
    "    trace = (trace-bl)/bl * 100\n",
    "    for t in times:\n",
    "        dic[t] = [trace[t]]\n",
    "\n",
    "    df = df.append(pd.DataFrame(dic), ignore_index=True)\n",
    "    \n",
    "df.to_csv(Path(r\"X:\\Maede\\data\\daure\\20211008\\traces_process.csv\"))\n",
    "\n",
    "times = list(range(buffer_idx[0]+buffer_idx[1]+240))\n",
    "df = pd.DataFrame()\n",
    "dic = {}\n",
    "\n",
    "for path in aib_paths:\n",
    "    path = Path(path)/'processed'\n",
    "    A, W = load_annotations(path)\n",
    "    names = [name.decode() for name in W.df[\"name\"]]\n",
    "    flow_file = os.path.join(path, \"flow_file.txt\")\n",
    "    flow, _ = load_flow_file(flow_file)\n",
    "    flow = [f  for f in flow if f!='CTX']\n",
    "    dic['animal'] = str(path).split('\\\\')[-2]\n",
    "    \n",
    "    \n",
    "    traces = get_trace_pher(path)\n",
    "\n",
    "    for neuron in aib_names:\n",
    "        dic['neuron'] = neuron\n",
    "        try:\n",
    "            trace = traces[names.index(neuron)]\n",
    "        except ValueError:\n",
    "            trace = np.zeros(traces.shape[-1])\n",
    "            trace[:] = np.nan\n",
    "        bl = np.nanmean(trace[buffer_idx[0]-20:buffer_idx[0]])\n",
    "        trace = (trace-bl)/bl * 100\n",
    "        for t in times:\n",
    "            dic[t] = [trace[t]]\n",
    "\n",
    "        df = df.append(pd.DataFrame(dic), ignore_index=True)\n",
    "\n",
    "df.to_csv(Path(r\"X:\\Maede\\data\\daure\\20211008\\traces_soma.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aia_odors = ['Pheromone', 'Control']\n",
    "aia_main_path = Path(r\"X:\\Mahdi\\Cynthia Chai\\PS9111\\microfluidics\")\n",
    "aia_paths = []\n",
    "\n",
    "for p1 in os.listdir(aia_main_path):\n",
    "    if os.path.isdir(os.path.join(aia_main_path, p1)):\n",
    "        for p2 in os.listdir(os.path.join(aia_main_path, p1)):\n",
    "            for p3 in os.listdir(os.path.join(aia_main_path, p1, p2)):\n",
    "                aia_paths.append(os.path.join(aia_main_path, p1, p2, p3))\n",
    "\n",
    "for path in aib_paths:\n",
    "    extract_traces(path)\n",
    "    \n",
    "\n",
    "def get_trace_aia(dataset):\n",
    "    p = Path(dataset)/'processed/traces/processes_traces.npy'\n",
    "    traces = np.load(p)\n",
    "    (frames,flow) = get_flow(dataset)\n",
    "    odor_idx = (int(frames[flow.index('Pheromone')]), int(frames[flow.index('Control')+1]))\n",
    "    t_idx = np.s_[odor_idx[0]-buffer_idx[0]:odor_idx[1]+buffer_idx[1]]\n",
    "    return traces[0, t_idx]\n",
    "\n",
    "def get_trace_aia_soma(dataset):\n",
    "    p = Path(dataset)/'processed/traces/traces.npy'\n",
    "    traces = np.load(p)\n",
    "    (frames,flow) = get_flow(dataset)\n",
    "    odor_idx = (int(frames[flow.index('Pheromone')]), int(frames[flow.index('Control')+1]))\n",
    "    t_idx = np.s_[odor_idx[0]-buffer_idx[0]:odor_idx[1]+buffer_idx[1]]\n",
    "    return traces[:, t_idx]\n",
    "\n",
    "times = list(range(buffer_idx[0]+buffer_idx[1]+240))\n",
    "df = pd.DataFrame()\n",
    "dic = {}\n",
    "for path in aia_paths[:]:\n",
    "    _, flow = get_flow(path)\n",
    "    flow = [f  for f in flow if f!='CTX']\n",
    "    animal_path, run = os.path.split(path)\n",
    "    _, dic['animal'] = os.path.split(animal_path)\n",
    "    dic['animal'] = dic['animal'][7:]\n",
    "    dic['run'] = run[4:]\n",
    "    dic['neuron'] = 'AIA process'\n",
    "        \n",
    "   \n",
    "    trace = get_trace_aia(path)\n",
    "    bl = np.nanmean(trace[buffer_idx[0]-20:buffer_idx[0]])\n",
    "    trace = (trace-bl)/bl * 100\n",
    "    for t in times:\n",
    "        dic[t] = [trace[t]]\n",
    "\n",
    "    df = df.append(pd.DataFrame(dic), ignore_index=True)\n",
    "    \n",
    "df.to_csv(Path(r\"X:\\Mahdi\\Cynthia Chai\\PS9111\\microfluidics\\process_traces.csv\"))\n",
    "\n",
    "times = list(range(buffer_idx[0]+buffer_idx[1]+240))\n",
    "df = pd.DataFrame()\n",
    "dic = {}\n",
    "\n",
    "for path in aia_paths:\n",
    "    print(path)\n",
    "    A, W = load_annotations(Path(path)/'processed')\n",
    "    names = [name.decode() for name in W.df[\"name\"]]\n",
    "    _, flow = get_flow(path)\n",
    "    flow = [f  for f in flow if f!='CTX']\n",
    "    animal_path, run = os.path.split(path)\n",
    "    _, dic['animal'] = os.path.split(animal_path)\n",
    "    dic['animal'] = dic['animal'][7:]\n",
    "    dic['run'] = run[4:]\n",
    "    \n",
    "    traces = get_trace_aia_soma(Path(path))\n",
    "\n",
    "    for neuron in ['AIAL', 'AIAR']:\n",
    "        dic['neuron'] = neuron\n",
    "        try:\n",
    "            trace = traces[names.index(neuron)]\n",
    "        except ValueError:\n",
    "            trace = np.zeros(traces.shape[-1])\n",
    "            trace[:] = np.nan\n",
    "        bl = np.nanmean(trace[buffer_idx[0]-20:buffer_idx[0]])\n",
    "        trace = (trace-bl)/bl * 100\n",
    "        for t in times:\n",
    "            dic[t] = [trace[t]]\n",
    "\n",
    "        df = df.append(pd.DataFrame(dic), ignore_index=True)\n",
    "        \n",
    "df.to_csv(Path(r\"X:\\Mahdi\\Cynthia Chai\\PS9111\\microfluidics\\soma_traces.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASK, ADL, AIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pher_odors = ['Pheromone', 'Control']\n",
    "neuron_names = ['ASKL', 'ADLL', 'AIAL', 'ASKR', 'ADLR', 'AIAR', 'AIA']\n",
    "\n",
    "main_path = Path(r\"Y:\\Mahdi\\Cynthia Chai\\PS8955\\microfluidics\")\n",
    "pher_paths = [os.path.join(main_path, r\"12_15_2020\\animal_6\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_15_2020\\animal_5\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_15_2020\\animal_4\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_22_2020\\animal_2\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_22_2020\\animal_5\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_22_2020\\animal_8\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_22_2020\\animal_10\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_22_2020\\animal_11\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_22_2020\\animal_12\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_22_2020\\animal_13\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_22_2020\\animal_14\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_23_2020\\animal_3\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_23_2020\\animal_8\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_23_2020\\animal_11\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_23_2020\\animal_12\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_23_2020\\animal_13\\run_1\\tracked\"),\n",
    "             os.path.join(main_path, r\"12_23_2020\\animal_14\\run_1\\tracked\")]\n",
    "\n",
    "for path in aib_paths:\n",
    "    extract_traces(path)\n",
    "\n",
    "def get_odor_trace_pher(dataset, odor):\n",
    "    p = Path(dataset)/'traces.npy'\n",
    "    traces = np.load(p)[1]\n",
    "    flow_file = os.path.join(dataset, \"flow_file.txt\")\n",
    "    flow, frames = load_flow_file(flow_file)\n",
    "    odor_idx = (int(frames[flow.index(odor)]), int(frames[flow.index(odor)+1]))\n",
    "    t_idx = np.s_[odor_idx[0]-buffer_idx[0]:odor_idx[1]+buffer_idx[1]]\n",
    "    return traces[:, t_idx]\n",
    "\n",
    "def get_trace_pher(dataset):\n",
    "    p = Path(dataset)/'traces.npy'\n",
    "    traces = np.load(p)[1]\n",
    "    flow_file = os.path.join(dataset, \"flow_file.txt\")\n",
    "    flow, frames = load_flow_file(flow_file)\n",
    "    odor_idx = (int(frames[flow.index('Pheromone')]), int(frames[flow.index('Control')+1]))\n",
    "    t_idx = np.s_[odor_idx[0]-buffer_idx[0]:odor_idx[1]+buffer_idx[1]]\n",
    "    return traces[:, t_idx]\n",
    "\n",
    "times = list(range(buffer_idx[0]+buffer_idx[1]+240))\n",
    "df = pd.DataFrame()\n",
    "dic = {}\n",
    "\n",
    "for path in pher_paths:\n",
    "    A, W = load_annotations(Path(path))\n",
    "    names = [name.decode() for name in W.df[\"name\"]]\n",
    "    flow_file = os.path.join(path, \"flow_file.txt\")\n",
    "    flow, _ = load_flow_file(flow_file)\n",
    "    flow = [f  for f in flow if f!='CTX']\n",
    "    animal_path, run = os.path.split(path[:-8])\n",
    "    date_path, dic['animal'] = os.path.split(animal_path)\n",
    "    _, dic['date'] = os.path.split(date_path)\n",
    "    dic['animal'] = dic['animal'][7:]\n",
    "    dic['run'] = run[4:]\n",
    "    \n",
    "    traces = get_trace_pher(path)\n",
    "\n",
    "    for neuron in neuron_names:\n",
    "        dic['neuron'] = neuron\n",
    "        try:\n",
    "            trace = traces[names.index(neuron)]\n",
    "        except ValueError:\n",
    "            trace = np.zeros(traces.shape[-1])\n",
    "            trace[:] = np.nan\n",
    "        bl = np.nanmean(trace[buffer_idx[0]-20:buffer_idx[0]])\n",
    "        trace = (trace-bl)/bl * 100\n",
    "        for t in times:\n",
    "            dic[t] = [trace[t]]\n",
    "\n",
    "        df = df.append(pd.DataFrame(dic), ignore_index=True)\n",
    "        \n",
    "df.to_csv(Path(r\"Y:\\Mahdi\\Cynthia Chai\\PS8955\\microfluidics\\traces2.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
